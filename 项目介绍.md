#基本原理
为了满足对一千万行数据的快速查询，我们使用了散列表来处理。即查询的关键字是电话号码，邮箱和名字，那么就分别对每行数据的这三个关键字按照一定的规则进行散列，然后根据散列的值对文件的数量取余的结果，将这条数据放到对应的文件里面去。
这样查询就可以直接对关键字hash取余后直接到对应的文件里查找，我们分成了100个文件，一个文件14m大小。这个大小的文件可以直接载入字典里，就算使用遍历的方式，也可以在0.25s左右查到对应的项。
#具体实现
##查找
根据关键字散列取余后的数直接到对应文件里面遍历查找。
##修改
找到对应的条目之后载入内存然后修改再覆盖回源文件。
##增加
对新的项的关键字取余后直接插入到对应的小文件末尾。
##删除
找到对应的条目之后载入内存然后删除再覆盖回源文件。
# 使用说明
我们的运行环境为 `Python 2.7`
## 数据处理
对于原数据，首先需要使用我们提供的脚本对其进行划分，
首先进入存放数据的目录 `Flask/database`, 将原数据 `card_person.data` 拷贝到当前目录，
接着运行数据划分脚本：
``` bash
python dataProcess.py
```
会依次产生：
``` bash
name: 0
name: 1
...
name: 99

phone: 0
phone: 1
...
phone: 99

email: 0
email: 1
...
email: 99
```
运行完成后会在 'name', 'phone', 'email' 目录下生成对应的数据
// 这个过程建议在 CPU 性能比较高的机器上进行，我们在实际使用中保存了数据文件 `card_person.data` 的3份副本以同时进行IO操作，在 MaxOS 系统下 i7-4800 的配置运行类似脚本大约耗时 20 分钟。。
## 运行服务
运行前需通过 `pip` 等工具安装 `Flask` 包：
``` bash
pip install flask
```
安装完成后进入服务器主文件所在目录下并运行服务：
``` bash
cd Flask
python flask.py
```
运行后在浏览器地址栏输入 `localhost:5000/index` 即可访问网页交互界面。
## 页面使用
+ 查询
 输入一项或多项关键字，如：姓名、电话或邮箱，点击查询按钮，即可在下方表格中显示查询结果。
+ 修改
 在查询结果的最后一栏“操作”中，点击“修改”，自动聚焦到该行第一列。修改结束后点击“确定”，修改后的数据就发送到数据库保存。
+ 删除
 在查询结果的最后一栏“操作”中，点击“删除”，删除请求成功后返回“删除成功”的提示。
+ 新增
 输入一项或多项关键字，如：姓名、电话或邮箱，点击插入按钮，新增的数据就发送到数据库保存，成功后会有“插入成功”的提示。
+ 清空
 点击清空按钮，则清空输入框及查询结果。

#其他说明
##使用B+树的尝试
刚开始试图使用将文件分块载入内存然后建一颗b+树的方式来完成数据的处理。这样时间的消耗这要在建树上，100万条数据需要4s，而全部数据需要70s（因为多了文件IO的时间），这样的时间性能肯定是不行的。
其次是对文件的重新写入，重新遍历B+树来完成对文件的覆盖写入时间开销过大，而如果把文件行数作为存储的键值对的值的话，查找与修改，增加可以很方便的定位的文件的对应位置（增加是在文件末尾，不会变动已有的行号），删除会把已有的行号全部打乱，为此，我们设想了一种解决方案：
即不再是对行号的精准定位，假设当前行号是X，那么就是在（X-n，X+n）的范围内搜索，其中n是某个执行删除的次数。当n大于一定值的时候就对这个文件重新建树。
使用B+树应该是可行的，因为难度较之散列较大而放弃。
##前后台对接的问题
前台返回的文件编码是ascii码，需要进行处理后，否则会报错。
#总结
这种方法虽然完成了题设的基本要求，但是缺点是明显的：
1. 对三个关键字的搜索就需要300个文件，每个关键字对应100个，总共3G，占用的磁盘空间过大；
2. 根据不同关键子查找修改后的同步问题，由于查找实质上是对每个关键字对应的100个文件的查找，那么其他关键字对应的文件需要再查找然后同时修改，这就增加的额外的时间开销。
3. 由于是hash，那么就无法完成通配符的功能，因为关键字的一部分的hash值明显不同。
   综上所述，这种方式劣势较大，且很难优化，最好还是采取B+树的方式去实现。
# 人员分工
+ 韦秋含：前端设计，编写交互逻辑。
+ 蒋琼宇：尝试写B+树以及将文件转换成二进制定长。
+ 李逸超：设计前后端接口、数据处理函数接口，调通项目
+ 吕严：编写数据处理函数，分割文件函数

所有成员都参与讨论了数据库算法的设计






